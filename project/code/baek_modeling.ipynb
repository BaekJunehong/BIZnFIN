{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIZ 프로젝트 : 부실기업 예측 모형에 관한 연구"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3 : 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "할거 : 21,22(2개년도)년도 딥러닝 모델 구축"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 라이브러리 및 데이터 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, GRU, Conv2D, MaxPooling2D, Flatten, Dropout, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "폰트 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "from matplotlib import rc\n",
    "\n",
    "# 운영 체제에 따라 폰트 설정\n",
    "if platform.system() == 'Windows':  # Windows 환경\n",
    "    rc('font', family='Malgun Gothic')  # 맑은 고딕\n",
    "\n",
    "# 음수 표시 가능하도록 설정\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 불러오기(21 to 22 2개년도 데이터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27603, 90)\n"
     ]
    }
   ],
   "source": [
    "RANDOM_STATE = 110\n",
    "\n",
    "data_21to22 = pd.read_csv(\"../../project/data/data_21to22.csv\", encoding='utf-8-sig', low_memory=False)\n",
    "print(data_21to22.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 종속 변수는 '2023/부실기업'으로 가정\n",
    "y = data_21to22['2023/부실기업']\n",
    "X = data_21to22.drop(columns=['2023/부실기업', '업체코드', '종목명'])\n",
    "\n",
    "# 데이터 분할 (70:30 비율)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딥러닝 모형 설정\n",
    "\n",
    "# 합성곱신경망 (CNN) - 은닉층 5개\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Reshape((X_train_scaled.shape[1], 1, 1), input_shape=(X_train_scaled.shape[1], 1))) # 입력층\n",
    "cnn_model.add(Conv2D(64, kernel_size=(2, 2), activation='relu', padding='same')) # 1번째 hidden layer\n",
    "cnn_model.add(MaxPooling2D(pool_size=(1, 1))) # 2번째 hidden layer\n",
    "cnn_model.add(Dropout(0.25)) # 3번째 hidden layer\n",
    "cnn_model.add(Flatten()) # 4번째 hidden layer\n",
    "cnn_model.add(Dense(128, activation='relu')) # 5번째 hidden layer\n",
    "cnn_model.add(Dropout(0.25)) # 6번째 hidden layer\n",
    "cnn_model.add(Dense(1, activation='sigmoid'))  # 출력층\n",
    "cnn_model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "# RNN-LSTM - 은닉층 2개\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(128, activation='relu', return_sequences=True, input_shape=(X_train_scaled.shape[1], 1))) # 1번째 hidden layer\n",
    "lstm_model.add(LSTM(128, activation='relu')) # 2번째 hidden layer\n",
    "lstm_model.add(Dense(1, activation='sigmoid')) # 출력층\n",
    "lstm_model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "# RNN-GRU - 은닉층 2개\n",
    "gru_model = Sequential()\n",
    "gru_model.add(GRU(128, activation='relu', return_sequences=True, input_shape=(X_train_scaled.shape[1], 1))) # 1번째 hidden layer\n",
    "gru_model.add(GRU(128, activation='relu')) # 2번째 hidden layer\n",
    "gru_model.add(Dense(1, activation='sigmoid')) # 출력층\n",
    "gru_model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "484/484 [==============================] - 6s 10ms/step - loss: 0.2140 - accuracy: 0.9081 - val_loss: 0.1786 - val_accuracy: 0.9195\n",
      "Epoch 2/200\n",
      "484/484 [==============================] - 5s 10ms/step - loss: 0.1723 - accuracy: 0.9239 - val_loss: 0.1946 - val_accuracy: 0.9133\n",
      "Epoch 3/200\n",
      "484/484 [==============================] - 5s 10ms/step - loss: 0.1623 - accuracy: 0.9275 - val_loss: 0.1624 - val_accuracy: 0.9247\n",
      "Epoch 4/200\n",
      "484/484 [==============================] - 5s 10ms/step - loss: 0.1515 - accuracy: 0.9333 - val_loss: 0.1658 - val_accuracy: 0.9257\n",
      "Epoch 5/200\n",
      "484/484 [==============================] - 5s 10ms/step - loss: 0.1449 - accuracy: 0.9351 - val_loss: 0.1560 - val_accuracy: 0.9314\n",
      "Epoch 6/200\n",
      "484/484 [==============================] - 5s 10ms/step - loss: 0.1397 - accuracy: 0.9393 - val_loss: 0.1593 - val_accuracy: 0.9288\n",
      "Epoch 7/200\n",
      "484/484 [==============================] - 5s 10ms/step - loss: 0.1336 - accuracy: 0.9420 - val_loss: 0.1713 - val_accuracy: 0.9278\n",
      "Epoch 8/200\n",
      "484/484 [==============================] - 5s 10ms/step - loss: 0.1302 - accuracy: 0.9424 - val_loss: 0.1714 - val_accuracy: 0.9312\n",
      "Epoch 9/200\n",
      "484/484 [==============================] - 5s 9ms/step - loss: 0.1272 - accuracy: 0.9435 - val_loss: 0.1641 - val_accuracy: 0.9312\n",
      "Epoch 10/200\n",
      "484/484 [==============================] - 5s 10ms/step - loss: 0.1244 - accuracy: 0.9458 - val_loss: 0.1658 - val_accuracy: 0.9320\n",
      "Epoch 11/200\n",
      "484/484 [==============================] - 5s 10ms/step - loss: 0.1199 - accuracy: 0.9476 - val_loss: 0.1692 - val_accuracy: 0.9307\n",
      "Epoch 12/200\n",
      "484/484 [==============================] - 5s 10ms/step - loss: 0.1141 - accuracy: 0.9495 - val_loss: 0.1642 - val_accuracy: 0.9309\n",
      "Epoch 13/200\n",
      "484/484 [==============================] - 5s 10ms/step - loss: 0.1117 - accuracy: 0.9519 - val_loss: 0.1673 - val_accuracy: 0.9322\n",
      "Epoch 14/200\n",
      "484/484 [==============================] - 5s 10ms/step - loss: 0.1093 - accuracy: 0.9534 - val_loss: 0.1860 - val_accuracy: 0.9307\n",
      "Epoch 15/200\n",
      "484/484 [==============================] - 5s 9ms/step - loss: 0.1046 - accuracy: 0.9560 - val_loss: 0.1836 - val_accuracy: 0.9304\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.1702 - accuracy: 0.9326\n",
      "CNN Accuracy: 0.9326168298721313\n",
      "Epoch 1/200\n",
      "484/484 [==============================] - 53s 107ms/step - loss: 12636689.0000 - accuracy: 0.8110 - val_loss: 0.4540 - val_accuracy: 0.8194\n",
      "Epoch 2/200\n",
      "484/484 [==============================] - 53s 110ms/step - loss: 4818.8545 - accuracy: 0.8147 - val_loss: 0.4400 - val_accuracy: 0.8173\n",
      "Epoch 3/200\n",
      "484/484 [==============================] - 53s 109ms/step - loss: 276223.9688 - accuracy: 0.8135 - val_loss: 0.4621 - val_accuracy: 0.8173\n",
      "Epoch 4/200\n",
      "484/484 [==============================] - 53s 110ms/step - loss: 0.4660 - accuracy: 0.8135 - val_loss: 0.4588 - val_accuracy: 0.8173\n",
      "Epoch 5/200\n",
      "484/484 [==============================] - 52s 107ms/step - loss: 12.1377 - accuracy: 0.8135 - val_loss: 0.4594 - val_accuracy: 0.8173\n",
      "Epoch 6/200\n",
      "484/484 [==============================] - 51s 106ms/step - loss: 0.4648 - accuracy: 0.8135 - val_loss: 0.4583 - val_accuracy: 0.8173\n",
      "Epoch 7/200\n",
      "484/484 [==============================] - 52s 107ms/step - loss: 0.4636 - accuracy: 0.8135 - val_loss: 0.4570 - val_accuracy: 0.8173\n",
      "Epoch 8/200\n",
      "484/484 [==============================] - 52s 108ms/step - loss: 0.4624 - accuracy: 0.8135 - val_loss: 0.4557 - val_accuracy: 0.8173\n",
      "Epoch 9/200\n",
      "484/484 [==============================] - 52s 108ms/step - loss: 0.4610 - accuracy: 0.8135 - val_loss: 0.4542 - val_accuracy: 0.8173\n",
      "Epoch 10/200\n",
      "484/484 [==============================] - 52s 107ms/step - loss: 0.4595 - accuracy: 0.8135 - val_loss: 0.4526 - val_accuracy: 0.8173\n",
      "Epoch 11/200\n",
      "484/484 [==============================] - 52s 107ms/step - loss: 0.4578 - accuracy: 0.8135 - val_loss: 0.4509 - val_accuracy: 0.8173\n",
      "Epoch 12/200\n",
      "484/484 [==============================] - 53s 108ms/step - loss: 0.4559 - accuracy: 0.8135 - val_loss: 0.4490 - val_accuracy: 0.8173\n",
      "259/259 [==============================] - 8s 31ms/step - loss: 0.4544 - accuracy: 0.8139\n",
      "LSTM Accuracy: 0.8139113783836365\n",
      "Epoch 1/200\n",
      "484/484 [==============================] - 45s 89ms/step - loss: 0.3628 - accuracy: 0.8517 - val_loss: 0.2970 - val_accuracy: 0.8655\n",
      "Epoch 2/200\n",
      "484/484 [==============================] - 45s 94ms/step - loss: 0.2780 - accuracy: 0.8829 - val_loss: 0.2886 - val_accuracy: 0.8831\n",
      "Epoch 3/200\n",
      "484/484 [==============================] - 45s 92ms/step - loss: 0.2694 - accuracy: 0.8894 - val_loss: 0.2610 - val_accuracy: 0.8965\n",
      "Epoch 4/200\n",
      "484/484 [==============================] - 45s 92ms/step - loss: 0.2584 - accuracy: 0.8901 - val_loss: 0.2493 - val_accuracy: 0.8887\n",
      "Epoch 5/200\n",
      "484/484 [==============================] - 45s 93ms/step - loss: 0.2348 - accuracy: 0.8988 - val_loss: 0.2300 - val_accuracy: 0.8965\n",
      "Epoch 6/200\n",
      "484/484 [==============================] - 45s 93ms/step - loss: 0.2239 - accuracy: 0.9003 - val_loss: 0.2224 - val_accuracy: 0.8962\n",
      "Epoch 7/200\n",
      "484/484 [==============================] - 45s 94ms/step - loss: 0.2205 - accuracy: 0.9023 - val_loss: 0.2272 - val_accuracy: 0.8965\n",
      "Epoch 8/200\n",
      "484/484 [==============================] - 45s 94ms/step - loss: 0.2141 - accuracy: 0.9053 - val_loss: 0.2137 - val_accuracy: 0.8994\n",
      "Epoch 9/200\n",
      "484/484 [==============================] - 45s 92ms/step - loss: 0.2093 - accuracy: 0.9090 - val_loss: 0.2090 - val_accuracy: 0.9019\n",
      "Epoch 10/200\n",
      "484/484 [==============================] - 45s 92ms/step - loss: 0.1936 - accuracy: 0.9129 - val_loss: 0.1926 - val_accuracy: 0.9136\n",
      "Epoch 11/200\n",
      "484/484 [==============================] - 45s 93ms/step - loss: 0.1802 - accuracy: 0.9205 - val_loss: 0.1893 - val_accuracy: 0.9154\n",
      "Epoch 12/200\n",
      "484/484 [==============================] - 45s 94ms/step - loss: 0.1696 - accuracy: 0.9273 - val_loss: 0.1756 - val_accuracy: 0.9232\n",
      "Epoch 13/200\n",
      "484/484 [==============================] - 45s 94ms/step - loss: 0.1661 - accuracy: 0.9257 - val_loss: 0.1835 - val_accuracy: 0.9133\n",
      "Epoch 14/200\n",
      "484/484 [==============================] - 45s 93ms/step - loss: 0.1617 - accuracy: 0.9306 - val_loss: 0.1918 - val_accuracy: 0.9082\n",
      "Epoch 15/200\n",
      "484/484 [==============================] - 45s 92ms/step - loss: 0.1563 - accuracy: 0.9320 - val_loss: 0.1715 - val_accuracy: 0.9232\n",
      "Epoch 16/200\n",
      "484/484 [==============================] - 47s 96ms/step - loss: 0.1518 - accuracy: 0.9341 - val_loss: 0.1690 - val_accuracy: 0.9247\n",
      "Epoch 17/200\n",
      "484/484 [==============================] - 46s 94ms/step - loss: 0.1516 - accuracy: 0.9348 - val_loss: 0.1670 - val_accuracy: 0.9276\n",
      "Epoch 18/200\n",
      "484/484 [==============================] - 44s 91ms/step - loss: 0.1504 - accuracy: 0.9349 - val_loss: 0.1725 - val_accuracy: 0.9182\n",
      "Epoch 19/200\n",
      "484/484 [==============================] - 45s 93ms/step - loss: 0.1469 - accuracy: 0.9361 - val_loss: 0.1645 - val_accuracy: 0.9273\n",
      "Epoch 20/200\n",
      "484/484 [==============================] - 45s 94ms/step - loss: 0.1460 - accuracy: 0.9380 - val_loss: 0.1608 - val_accuracy: 0.9299\n",
      "Epoch 21/200\n",
      "484/484 [==============================] - 47s 97ms/step - loss: 0.1429 - accuracy: 0.9380 - val_loss: 0.1747 - val_accuracy: 0.9247\n",
      "Epoch 22/200\n",
      "484/484 [==============================] - 47s 97ms/step - loss: 0.1420 - accuracy: 0.9389 - val_loss: 0.1568 - val_accuracy: 0.9299\n",
      "Epoch 23/200\n",
      "484/484 [==============================] - 46s 96ms/step - loss: 0.1385 - accuracy: 0.9387 - val_loss: 0.1605 - val_accuracy: 0.9301\n",
      "Epoch 24/200\n",
      "484/484 [==============================] - 46s 96ms/step - loss: 0.1359 - accuracy: 0.9402 - val_loss: 0.1640 - val_accuracy: 0.9288\n",
      "Epoch 25/200\n",
      "484/484 [==============================] - 44s 92ms/step - loss: 0.1329 - accuracy: 0.9418 - val_loss: 0.1590 - val_accuracy: 0.9317\n",
      "Epoch 26/200\n",
      "484/484 [==============================] - 45s 93ms/step - loss: 0.1291 - accuracy: 0.9435 - val_loss: 0.1633 - val_accuracy: 0.9286\n",
      "Epoch 27/200\n",
      "484/484 [==============================] - 45s 93ms/step - loss: 0.1292 - accuracy: 0.9442 - val_loss: 0.1631 - val_accuracy: 0.9338\n",
      "Epoch 28/200\n",
      "484/484 [==============================] - 47s 97ms/step - loss: 0.1257 - accuracy: 0.9459 - val_loss: 0.1768 - val_accuracy: 0.9270\n",
      "Epoch 29/200\n",
      "484/484 [==============================] - 46s 95ms/step - loss: 0.1238 - accuracy: 0.9458 - val_loss: 0.1708 - val_accuracy: 0.9283\n",
      "Epoch 30/200\n",
      "484/484 [==============================] - 46s 94ms/step - loss: 0.1226 - accuracy: 0.9468 - val_loss: 0.1792 - val_accuracy: 0.9276\n",
      "Epoch 31/200\n",
      "484/484 [==============================] - 46s 95ms/step - loss: 0.1187 - accuracy: 0.9517 - val_loss: 0.1706 - val_accuracy: 0.9232\n",
      "Epoch 32/200\n",
      "484/484 [==============================] - 47s 96ms/step - loss: 0.1169 - accuracy: 0.9484 - val_loss: 0.1793 - val_accuracy: 0.9242\n",
      "259/259 [==============================] - 6s 23ms/step - loss: 0.1698 - accuracy: 0.9341\n",
      "GRU Accuracy: 0.9340659379959106\n"
     ]
    }
   ],
   "source": [
    "# 딥러닝 모형 학습 및 평가\n",
    "\n",
    "# CNN 학습 및 평가\n",
    "X_train_cnn = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1, 1))\n",
    "X_test_cnn = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1, 1))\n",
    "cnn_model.fit(X_train_cnn, y_train, epochs=200, batch_size=32, validation_split=0.2, callbacks=[tf.keras.callbacks.EarlyStopping(patience=10)])\n",
    "cnn_accuracy = cnn_model.evaluate(X_test_cnn, y_test)[1]\n",
    "print(f\"CNN Accuracy: {cnn_accuracy}\")\n",
    "\n",
    "# RNN-LSTM 학습 및 평가\n",
    "X_train_lstm = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
    "X_test_lstm = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
    "lstm_model.fit(X_train_lstm, y_train, epochs=200, batch_size=32, validation_split=0.2, callbacks=[tf.keras.callbacks.EarlyStopping(patience=10)])\n",
    "lstm_accuracy = lstm_model.evaluate(X_test_lstm, y_test)[1]\n",
    "print(f\"LSTM Accuracy: {lstm_accuracy}\")\n",
    "\n",
    "# RNN-GRU 학습 및 평가\n",
    "gru_model.fit(X_train_lstm, y_train, epochs=200, batch_size=32, validation_split=0.2, callbacks=[tf.keras.callbacks.EarlyStopping(patience=10)])\n",
    "gru_accuracy = gru_model.evaluate(X_test_lstm, y_test)[1]\n",
    "print(f\"GRU Accuracy: {gru_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Learning Models: CNN, LSTM, GRU\n",
      "CNN Accuracy: 0.9326168298721313\n",
      "LSTM Accuracy: 0.8139113783836365\n",
      "GRU Accuracy: 0.9340659379959106\n"
     ]
    }
   ],
   "source": [
    "print(f\"Deep Learning Models: CNN, LSTM, GRU\")\n",
    "print(f\"CNN Accuracy: {cnn_accuracy}\")\n",
    "print(f\"LSTM Accuracy: {lstm_accuracy}\")\n",
    "print(f\"GRU Accuracy: {gru_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
